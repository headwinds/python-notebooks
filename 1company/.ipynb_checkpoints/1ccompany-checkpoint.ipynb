{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "In this competition you will work with a challenging time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company. \n",
    "\n",
    "We are asking you to predict total sales for every product and store in the next month. By solving this competition you will be able to apply and enhance your data science skills.\n",
    "\n",
    "You are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.\n",
    "\n",
    "### File descriptions\n",
    "* sales_train.csv - the training set. Daily historical data from January 2013 to October 2015. I should sample a dataset from the last 1000 rows\n",
    "* test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.\n",
    "* sample_submission.csv - a sample submission file in the correct format.\n",
    "* items.csv - supplemental information about the items/products.\n",
    "* item_categories.csv  - supplemental information about the items categories.\n",
    "* shops.csv- supplemental information about the shops.\n",
    "\n",
    "### Data fields\n",
    "* ID - an Id that represents a (Shop, Item) tuple within the test set\n",
    "* shop_id - unique identifier of a shop\n",
    "* item_id - unique identifier of a product\n",
    "* item_category_id - unique identifier of item category\n",
    "* item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n",
    "* item_price - current price of an item\n",
    "* date - date in format dd/mm/yyyy\n",
    "* date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n",
    "* item_name - name of item\n",
    "* shop_name - name of shop\n",
    "* item_category_name - name of item category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import nltk, datetime\n",
    "\n",
    "train = pd.read_csv('./sales_train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "items = pd.read_csv('./items.csv')\n",
    "item_cats = pd.read_csv('./item_categories.csv')\n",
    "shops = pd.read_csv('./shops.csv')\n",
    "print('train:', train.shape, 'test:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals:\n",
    "\n",
    "* analyze the data and clean it \n",
    "* convert categorical data into numeric \n",
    "* tally the products to determine month sales for train data - how many items were sold\n",
    "\n",
    "Problems to Solve:\n",
    "\n",
    "* the train data probably has different shops and products that the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Features\n",
    "feature_cnt = 25\n",
    "tfidf = feature_extraction.text.TfidfVectorizer(max_features=feature_cnt)\n",
    "item_cats['item_category_name_len'] = item_cats['item_category_name'].map(len)  #Lenth of Item Category Description\n",
    "item_cats['item_category_name_wc'] = item_cats['item_category_name'].map(lambda x: len(str(x).split(' '))) #Item Category Description Word Count\n",
    "txtFeatures = pd.DataFrame(tfidf.fit_transform(item_cats['item_category_name']).toarray())\n",
    "cols = txtFeatures.columns\n",
    "for i in range(feature_cnt):\n",
    "    item_cats['item_category_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\n",
    "item_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Features\n",
    "feature_cnt = 25\n",
    "tfidf = feature_extraction.text.TfidfVectorizer(max_features=feature_cnt)\n",
    "shops['shop_name_len'] = shops['shop_name'].map(len)  #Lenth of Shop Name\n",
    "shops['shop_name_wc'] = shops['shop_name'].map(lambda x: len(str(x).split(' '))) #Shop Name Word Count\n",
    "txtFeatures = pd.DataFrame(tfidf.fit_transform(shops['shop_name']).toarray())\n",
    "cols = txtFeatures.columns\n",
    "for i in range(feature_cnt):\n",
    "    shops['shop_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Monthly\n",
    "train['date'] = pd.to_datetime(train['date'], format='%d.%m.%Y')\n",
    "train['month'] = train['date'].dt.month\n",
    "train['year'] = train['date'].dt.year\n",
    "train = train.drop(['date','item_price'], axis=1)\n",
    "train = train.groupby([c for c in train.columns if c not in ['item_cnt_day']], as_index=False)[['item_cnt_day']].sum()\n",
    "train = train.rename(columns={'item_cnt_day':'item_cnt_month'})\n",
    "#Monthly Mean\n",
    "shop_item_monthly_mean = train[['shop_id','item_id','item_cnt_month']].groupby(['shop_id','item_id'], as_index=False)[['item_cnt_month']].mean()\n",
    "shop_item_monthly_mean = shop_item_monthly_mean.rename(columns={'item_cnt_month':'item_cnt_month_mean'})\n",
    "#Add Mean Feature\n",
    "train = pd.merge(train, shop_item_monthly_mean, how='left', on=['shop_id','item_id'])\n",
    "#Last Month (Oct 2015)\n",
    "shop_item_prev_month = train[train['date_block_num']==33][['shop_id','item_id','item_cnt_month']]\n",
    "shop_item_prev_month = shop_item_prev_month.rename(columns={'item_cnt_month':'item_cnt_prev_month'})\n",
    "shop_item_prev_month.head()\n",
    "#Add Previous Month Feature\n",
    "train = pd.merge(train, shop_item_prev_month, how='left', on=['shop_id','item_id']).fillna(0.)\n",
    "#Items features\n",
    "train = pd.merge(train, items, how='left', on='item_id')\n",
    "#Item Category features\n",
    "train = pd.merge(train, item_cats, how='left', on='item_category_id')\n",
    "#Shops features\n",
    "train = pd.merge(train, shops, how='left', on='shop_id')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['month'] = 11\n",
    "test['year'] = 2015\n",
    "test['date_block_num'] = 34\n",
    "#Add Mean Feature\n",
    "test = pd.merge(test, shop_item_monthly_mean, how='left', on=['shop_id','item_id']).fillna(0.)\n",
    "#Add Previous Month Feature\n",
    "test = pd.merge(test, shop_item_prev_month, how='left', on=['shop_id','item_id']).fillna(0.)\n",
    "#Items features\n",
    "test = pd.merge(test, items, how='left', on='item_id')\n",
    "#Item Category features\n",
    "test = pd.merge(test, item_cats, how='left', on='item_category_id')\n",
    "#Shops features\n",
    "test = pd.merge(test, shops, how='left', on='shop_id')\n",
    "test['item_cnt_month'] = 0.\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df_all = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "stores_hm = df_all.pivot_table(index='shop_id', columns='item_category_id', values='item_cnt_month', aggfunc='count', fill_value=0)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "_ = sns.heatmap(stores_hm, ax=ax, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_hm = test.pivot_table(index='shop_id', columns='item_category_id', values='item_cnt_month', aggfunc='count', fill_value=0)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "_ = sns.heatmap(stores_hm, ax=ax, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['shop_name','item_name','item_category_name']:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train[c].unique())+list(test[c].unique()))\n",
    "    train[c] = lbl.transform(train[c].astype(str))\n",
    "    test[c] = lbl.transform(test[c].astype(str))\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [c for c in train.columns if c not in ['item_cnt_month']]\n",
    "#Validation Hold Out Month\n",
    "x1 = train[train['date_block_num']<33]\n",
    "y1 = np.log1p(x1['item_cnt_month'].clip(0.,20.))\n",
    "x1 = x1[col]\n",
    "x2 = train[train['date_block_num']==33]\n",
    "y2 = np.log1p(x2['item_cnt_month'].clip(0.,20.))\n",
    "x2 = x2[col]\n",
    "\n",
    "reg = ensemble.ExtraTreesRegressor(n_estimators=25, n_jobs=-1, max_depth=15, random_state=18)\n",
    "reg.fit(x1,y1)\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y2.clip(0.,20.),reg.predict(x2).clip(0.,20.))))\n",
    "#full train\n",
    "reg.fit(train[col],train['item_cnt_month'].clip(0.,20.))\n",
    "test['item_cnt_month'] = reg.predict(test[col]).clip(0.,20.)\n",
    "test[['ID','item_cnt_month']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from multiprocessing import *\n",
    "\n",
    "#XGBoost\n",
    "def xgb_rmse(preds, y):\n",
    "    y = y.get_label()\n",
    "    score = np.sqrt(metrics.mean_squared_error(y.clip(0.,20.), preds.clip(0.,20.)))\n",
    "    return 'RMSE', score\n",
    "\n",
    "#params = {'eta': 0.2, 'max_depth': 4, 'objective': 'reg:linear', 'eval_metric': 'rmse', 'seed': 18, 'silent': True}\n",
    "#watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "#xgb_model = xgb.train(params, xgb.DMatrix(x1, y1), 100,  watchlist, verbose_eval=10, feval=xgb_rmse, maximize=False, early_stopping_rounds=20)\n",
    "#test['item_cnt_month'] = xgb_model.predict(xgb.DMatrix(test[col]), ntree_limit=xgb_model.best_ntree_limit)\n",
    "#test[['ID','item_cnt_month']].to_csv('xgb_submission.csv', index=False)\n",
    "\n",
    "#LightGBM\n",
    "def lgb_rmse(preds, y):\n",
    "    y = np.array(list(y.get_label()))\n",
    "    score = np.sqrt(metrics.mean_squared_error(y.clip(0.,20.), preds.clip(0.,20.)))\n",
    "    return 'RMSE', score, False\n",
    "\n",
    "# params = {'learning_rate': 0.2, 'max_depth': 7, 'boosting': 'gbdt', 'objective': 'regression', 'metric': 'mse', 'is_training_metric': False, 'seed': 18}\n",
    "# lgb_model = lgb.train(params, lgb.Dataset(x1, label=y1), 100, lgb.Dataset(x2, label=y2), feval=lgb_rmse, verbose_eval=10, early_stopping_rounds=20)\n",
    "# test['item_cnt_month'] = lgb_model.predict(test[col], num_iteration=lgb_model.best_iteration)\n",
    "# test[['ID','item_cnt_month']].to_csv('lgb_submission.csv', index=False)\n",
    "\n",
    "#CatBoost\n",
    "# cb_model = CatBoostRegressor(iterations=100, learning_rate=0.2, depth=7, loss_function='RMSE', eval_metric='RMSE', random_seed=18, od_type='Iter', od_wait=20) \n",
    "# cb_model.fit(x1, y1, eval_set=(x2, y2), use_best_model=True, verbose=False)\n",
    "# print('RMSE:', np.sqrt(metrics.mean_squared_error(y2.clip(0.,20.), cb_model.predict(x2).clip(0.,20.))))\n",
    "# test['item_cnt_month'] += cb_model.predict(test[col])\n",
    "# test['item_cnt_month'] /= 2\n",
    "# test[['ID','item_cnt_month']].to_csv('cb_blend_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['item_cnt_month'] = np.expm1(test['item_cnt_month'])\n",
    "#test[['ID','item_cnt_month']].to_csv('cb_submission_exp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
